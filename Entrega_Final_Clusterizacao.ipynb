{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Inteligência Artificial para Clustericação [24E4_2]\n",
    "\n",
    "## PROJETO DA DISCIPLINA - ENTREGA FINAL\n",
    "\n",
    "### Aluno: Marcio Feldmann\n",
    "### Repositório Público GitHub: https://github.com/marciofeld/infnet_algoritmos_clusterizacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Infraestrutura\n",
    "\n",
    "Para as questões a seguir, você deverá executar códigos em um notebook Jupyter, rodando em ambiente local, certifique-se que:\n",
    "\n",
    "1. Você está rodando em Python 3.9+\n",
    "2. Você está usando um ambiente virtual: Virtualenv ou Anaconda\n",
    "3. Todas as bibliotecas usadas nesse exercícios estão instaladas em um ambiente virtual específico\n",
    "4. Gere um arquivo de requerimentos (requirements.txt) com os pacotes necessários. É necessário se certificar que a versão do pacote está disponibilizada.\n",
    "5. Tire um printscreen do ambiente que será usado rodando em sua máquina.\n",
    "6. Disponibilize os códigos gerados, assim como os artefatos acessórios (requirements.txt) e instruções em um repositório GIT público. (se isso não for feito, o diretório com esses arquivos deverá ser enviado compactado no moodle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1 - Importação de bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 - Escolha de base de dados\n",
    "\n",
    "Para as questões a seguir, usaremos uma base de dados e faremos a análise exploratória dos dados, antes da clusterização.\n",
    "\n",
    "1. Baixe os dados disponibilizados na plataforma Kaggle sobre dados sócio-econômicos e de saúde que determinam o índice de desenvolvimento de um país. Esses dados estão disponibilizados através do link: [https://www.kaggle.com/datasets/rohan0301/unsupervised-learning-on-country-data](https://www.kaggle.com/datasets/rohan0301/unsupervised-learning-on-country-data)\n",
    "2. Quantos países existem no dataset?\n",
    "3. Mostre através de gráficos a faixa dinâmica das variáveis que serão usadas nas tarefas de clusterização. Analise os resultados mostrados. O que deve ser feito com os dados antes da etapa de clusterização?\n",
    "4. Realize o pré-processamento adequado dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Importação da Base de Dados\n",
    "# INPUT: Country-data.csv\n",
    "\n",
    "dataset = pd.read_csv('Country-data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Exercício 2\n",
    "\n",
    "qnt_paises = dataset['country'].nunique()\n",
    "print('\\033[1mParte 2 - Exercício 2 - Quantos países existem no dataset?\\033[0m\\n')\n",
    "print(f'Resposta do Exercício 2: \\033[1m{qnt_paises}\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das colunas de dados\n",
    "\n",
    "colunas_de_dados = ['child_mort','exports','health','imports','income','inflation','life_expec','total_fer','gdpp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Exercício 3 - Mostre através de gráficos a faixa dinâmica das variáveis que serão utilizadas nas tarefas de clusterização.\n",
    "\n",
    "n_linhas = 3\n",
    "n_colunas = 3\n",
    "\n",
    "fig, axes = plt.subplots(n_linhas, n_colunas, figsize=(15, 12), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, coluna in enumerate(colunas_de_dados):\n",
    "    axes[i].boxplot(dataset[coluna])\n",
    "    axes[i].set_title(coluna)\n",
    "    axes[i].set_xlabel(coluna)\n",
    "\n",
    "fig.supylabel('Valores Originais')\n",
    "fig.suptitle('Parte 2 - Exercício 3 - Faixa Dinâmica das Variáveis', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Exercício 3 - Analise os resultados mostrados. O que deve ser feito com os dados antes da etapa de clusterização?\n",
    "\n",
    "print('\\033[1mParte 2 - Exercício 3 - Resposta\\033[0m\\n')\n",
    "print('Após a análise dos resultados da faixa dinâmica das variáveis, verifico que devemos executar uma normalização de todas as colunas de dados na etapa de pré-processamento.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Exercício 4 - Realize o pré-processamento adequado dos dados (1)\n",
    "\n",
    "# Mapeando nomes de países para números\n",
    "pais_para_numero = {country: i for i, country in enumerate(dataset['country'])}\n",
    "# Mapeando números para nomes de países\n",
    "numero_para_pais = {i: country for country, i in pais_para_numero.items()}\n",
    "\n",
    "print('\\033[1mDicionário: pais_para_numero\\033[0m')\n",
    "print(pais_para_numero)\n",
    "print('\\033[1mDicionário: numero_para_pais\\033[0m')\n",
    "print(numero_para_pais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Exercício 4 - Realize o pré-processamento adequado dos dados (2)\n",
    "\n",
    "# Realizando normalização de dados\n",
    "scaler = MinMaxScaler()\n",
    "dataset_normalizado = scaler.fit_transform(dataset[colunas_de_dados])\n",
    "dataset_normalizado = pd.DataFrame(dataset_normalizado, columns=colunas_de_dados)\n",
    "\n",
    "# Inserindo na primeira coluna do `dataset_normalizado` os códigos numéricos de cada país\n",
    "dataset_normalizado.insert(0, 'country_code', dataset['country'].map(pais_para_numero))\n",
    "\n",
    "print('\\033[1mDataset Normalizado com códigos numéricos para os países:\\033[0m')\n",
    "print(dataset_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 - Exercício 4 - Realize o pré-processamento adequado dos dados (3)\n",
    "\n",
    "n_linhas = 3\n",
    "n_colunas = 3\n",
    "\n",
    "fig, axes = plt.subplots(n_linhas, n_colunas, figsize=(15, 12), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, coluna in enumerate(colunas_de_dados):\n",
    "    axes[i].boxplot(dataset_normalizado[coluna])\n",
    "    axes[i].set_title(coluna)\n",
    "    axes[i].set_xlabel(coluna)\n",
    "\n",
    "fig.supylabel('Valores Normalizados')\n",
    "fig.suptitle('Parte 2 - Exercício 4 - Dados Normalizados', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 - Clusterização\n",
    "\n",
    "Para os dados pré-processados da etapa anterior você irá:\n",
    "\n",
    "1. Realizar o agrupamento dos países em 3 grupos distintos. Para tal, use:\n",
    "    - a. K-Médias\n",
    "    - b. Clusterização Hierárquica\n",
    "2. Para os resultados, do K-Médias:\n",
    "    - a. Interprete cada um dos clusters obtidos citando:\n",
    "        - i. Qual a distribuição das dimensões em cada grupo\n",
    "        - ii. O país, de acordo com o algoritmo, melhor representa o seu agrupamento. Justifique\n",
    "3. Para os resultados da Clusterização Hierárquica, apresente o dendograma e interprete os resultados\n",
    "4. Compare os dois resultados, aponte as semelhanças e diferenças e interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de número de clusters\n",
    "\n",
    "n_clusters=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 1.a - Agrupamento dos países em 3 grupos distintos usando K-Médias\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters,random_state=20)\n",
    "dataset_normalizado['Cluster_Kmeans'] = kmeans.fit_predict(dataset_normalizado[colunas_de_dados])\n",
    "\n",
    "print('\\033[1mParte 3 - Exercício 1.a - Agrupamento dos países em 3 grupos distintos usando K-Médias\\033[0m')\n",
    "print(\n",
    "    pd.DataFrame({\n",
    "        'Country': dataset_normalizado['country_code'].map(numero_para_pais),\n",
    "        'Cluster_Kmeans': dataset_normalizado['Cluster_Kmeans']\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 1.b - Agrupamento dos países em 3 grupos distintos usando Clusterização Hierárquica\n",
    "\n",
    "data = dataset_normalizado[colunas_de_dados].values\n",
    "\n",
    "clusterizacao_hierarquica = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "dataset_normalizado['Cluster_Hierarquico'] = clusterizacao_hierarquica.fit_predict(data)\n",
    "\n",
    "print('\\033[1mParte 3 - Exercício 1.b - Agrupamento dos países em 3 grupos distintos usando Clusterização Hierárquica\\033[0m')\n",
    "print(\n",
    "    pd.DataFrame({\n",
    "        'Country': dataset_normalizado['country_code'].map(numero_para_pais),\n",
    "        'Cluster_Hierarquico': dataset_normalizado['Cluster_Hierarquico']\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 2.a.i - Para os resultados do K-Médias, interprete cada um dos clusters obtidos citando: Qual a distribuição das dimensões em cada grupo (1)\n",
    "\n",
    "distribuicao_clusters = dataset_normalizado.groupby('Cluster_Kmeans').mean()\n",
    "print('\\033[1mParte 3 - Exercício 2.a.i(1) - Distribuição das dimensões em cada grupo utilizando o K-Médias\\033[0m')\n",
    "print(distribuicao_clusters.iloc[:, 1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 2.a.i - Para os resultados do K-Médias, interprete cada um dos clusters obtidos citando: Qual a distribuição das dimensões em cada grupo (2)\n",
    "\n",
    "print('\\033[1mParte 3 - Exercício 2.a.i - Para os resultados do K-Médias, interprete cada um dos clusters obtidos citando: Qual a distribuição das dimensões em cada grupo\\033[0m\\n')\n",
    "\n",
    "def classificar_cluster(valores):\n",
    "    # Classificar os clusters automaticamente com base em dimensões-chave (income, life_expec e child_mort)\n",
    "    ## Países desenvolvidos possuem alta renda (income), alta expectativa de vida (life_expec) e baixa mortalidade infantil (child_mort)\n",
    "    if valores['income'] > 0.3 and valores['life_expec'] > 0.9 and valores['child_mort'] < 0.05:\n",
    "        return 'Países desenvolvidos'\n",
    "    ## Países subdesenvolvidos possuem baixa renda (income), baixa expectativa de vida (life_expec) e alta mortalidade infantil (child_mort)\n",
    "    elif valores['income'] < 0.1 and valores['life_expec'] < 0.6 and valores['child_mort'] > 0.4:\n",
    "        return 'Países subdesenvolvidos'\n",
    "    ## Países em desenvolvimento possuem valores intermediários\n",
    "    else:\n",
    "        return 'Países em desenvolvimento'\n",
    "\n",
    "def interpretar_clusters(distribuicao):\n",
    "    interpretacoes = []\n",
    "    for cluster, valores in distribuicao.iterrows():\n",
    "        tipo_cluster = classificar_cluster(valores)\n",
    "        interpretacao = (\n",
    "            f'\\033[1mCluster {cluster}: {tipo_cluster}\\033[0m\\n'\n",
    "            f'- Mortalidade infantil: {valores['child_mort']:.4f}\\n'\n",
    "            f'- Expectativa de vida: {valores['life_expec']:.4f}\\n'\n",
    "            f'- Renda per capita: {valores['income']:.4f}\\n'\n",
    "            f'- Inflação: {valores['inflation']:.4f}\\n'\n",
    "            f'- PIB: {valores['gdpp']:.4f}\\n'\n",
    "        )\n",
    "        interpretacoes.append(interpretacao)\n",
    "    return interpretacoes\n",
    "\n",
    "interpretacoes = interpretar_clusters(distribuicao_clusters)\n",
    "\n",
    "for interpretacao in interpretacoes:\n",
    "    print(interpretacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 2.a.ii - Para os resultados do K-Médias, interprete cada um dos clusters obtidos citando: O país, de acordo com o algoritmo, melhor representa o seu agrupamento. Justifique (1)\n",
    "\n",
    "centroides = kmeans.cluster_centers_\n",
    "distancias = cdist(dataset_normalizado[colunas_de_dados], centroides, metric='euclidean')\n",
    "\n",
    "representantes = {}\n",
    "for cluster in range(n_clusters):\n",
    "    indices_cluster = dataset_normalizado['Cluster_Kmeans'] == cluster\n",
    "    distancias_cluster = distancias[indices_cluster, cluster]\n",
    "    indice_mais_proximo = np.argmin(distancias_cluster)\n",
    "    pais_mais_proximo = dataset_normalizado.loc[indices_cluster].iloc[indice_mais_proximo]['country_code']\n",
    "    representantes[cluster] = numero_para_pais[pais_mais_proximo]\n",
    "\n",
    "print('\\033[1mParte 3 - Exercício 2.a.ii(1) - Distribuição das dimensões em cada grupo utilizando o K-Médias\\033[0m')\n",
    "print('\\033[1mPaíses que melhor representam cada agrupamento:\\033[0m\\n')\n",
    "for cluster, pais in representantes.items():\n",
    "    print(f'\\033[1mCluster {cluster}:\\033[0m {pais}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 2.a.ii - Para os resultados do K-Médias, interprete cada um dos clusters obtidos citando: O país, de acordo com o algoritmo, melhor representa o seu agrupamento. Justifique (2)\n",
    "\n",
    "print('\\033[1mParte 3 - Exercício 2.a.ii(2) - Distribuição das dimensões em cada grupo utilizando o K-Médias - Justificativas\\033[0m\\n')\n",
    "\n",
    "def justificar_representantes(representantes, centroides, dataset, colunas, numero_para_pais):\n",
    "    justificativas = []\n",
    "    \n",
    "    for cluster, pais in representantes.items():\n",
    "        country_code = list(numero_para_pais.keys())[list(numero_para_pais.values()).index(pais)]\n",
    "        valores_pais = dataset[dataset['country_code'] == country_code][colunas].iloc[0]\n",
    "        valores_centroide = centroides[cluster]\n",
    "        diferencas = abs(valores_pais - valores_centroide)\n",
    "        \n",
    "        menores_indices = diferencas.argsort()[:3]\n",
    "        menores_colunas = [colunas[i] for i in menores_indices]\n",
    "        menores_diferencas = [diferencas.iloc[i] for i in menores_indices]\n",
    "        \n",
    "        justificativa = (\n",
    "            f'\\033[1mCluster {cluster} - Representante: {pais}\\033[0m\\n'\n",
    "            f'Este país foi escolhido porque possui valores próximos ao centróide do cluster.\\n'\n",
    "            f'As 3 dimensões com menor diferença absoluta entre o país \\033[1m{pais}\\033[0m e o centróide do cluster são:\\n'\n",
    "        )\n",
    "        \n",
    "        for coluna, diferenca in zip(menores_colunas, menores_diferencas):\n",
    "            justificativa += f'- {coluna}: {diferenca:.4f}\\n'\n",
    "        \n",
    "        justificativas.append(justificativa)\n",
    "    \n",
    "    return justificativas\n",
    "\n",
    "justificativas = justificar_representantes(representantes, centroides, dataset_normalizado, colunas_de_dados, numero_para_pais)\n",
    "\n",
    "for justificativa in justificativas:\n",
    "    print(justificativa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 3 - Para os resultados da Clusterização Hierárquica, apresente o dendograma e interprete os resultados (1)\n",
    "\n",
    "# Criar a matriz de linkagem para o dendrograma usando o método 'ward'\n",
    "linkage_matrix = linkage(data, method='ward')\n",
    "\n",
    "# Função para plotar o dendrograma\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title('Parte 3 - Exercício 3 - Dendograma da Clusterização Hierárquica', fontsize=16)\n",
    "plt.xlabel('Países', fontsize=12)\n",
    "plt.ylabel('Distância Euclidiana', fontsize=12)\n",
    "\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    labels=dataset_normalizado['country_code'].map(numero_para_pais).values, leaf_rotation=90, leaf_font_size=6,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 3 - Para os resultados da Clusterização Hierárquica, apresente o dendograma e interprete os resultados (2)\n",
    "\n",
    "# Listar os países em cada cluster hierárquico\n",
    "for cluster in sorted(dataset_normalizado['Cluster_Hierarquico'].unique()):\n",
    "    print(f'Cluster {cluster}:')\n",
    "    print(dataset_normalizado[dataset_normalizado['Cluster_Hierarquico'] == cluster]['country_code']\n",
    "          .map(numero_para_pais)\n",
    "          .tolist())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 3 - Para os resultados da Clusterização Hierárquica, apresente o dendograma e interprete os resultados.\n",
    "\n",
    "print('## Justificativa dos Clusters - Dendograma da Clusterização Hierárquica')\n",
    "\n",
    "## Cluster 1\n",
    "print('\\n\\033[1m### Cluster 1 (Laranja - Subdesenvolvidos)\\033[0m')\n",
    "print('- \\033[1mPaíses incluídos\\033[0m: Camarões, Angola, Serra Leoa, Congo, entre outros.')\n",
    "print('- \\033[1mJustificação\\033[0m:')\n",
    "print('  - Esses países compartilham baixos indicadores socioeconômicos.')\n",
    "print('  - \\033[1mCaracterísticas principais\\033[0m:')\n",
    "print('    - \\033[1mRenda per capita\\033[0m: Baixa.')\n",
    "print('    - \\033[1mMortalidade infantil\\033[0m: Alta.')\n",
    "print('    - \\033[1mExpectativa de vida\\033[0m: Baixa.')\n",
    "\n",
    "## Cluster 2\n",
    "print('\\n\\033[1m### Cluster 2 (Verde à esquerda - Em Desenvolvimento)\\033[0m')\n",
    "print('- \\033[1mPaíses incluídos\\033[0m: Micronésia, Brasil, Paraguai, entre outros.')\n",
    "print('- \\033[1mJustificação\\033[0m:')\n",
    "print('  - Estes países possuem características intermediárias, tanto sociais quanto econômicas.')\n",
    "print('  - \\033[1mCaracterísticas principais\\033[0m:')\n",
    "print('    - \\033[1mRenda per capita\\033[0m: Moderada.')\n",
    "print('    - \\033[1mMortalidade infantil\\033[0m: Moderada.')\n",
    "print('    - \\033[1mExpectativa de vida\\033[0m: Moderada.')\n",
    "\n",
    "## Cluster 3\n",
    "print('\\n\\033[1m### Cluster 3 (Verde à direita - Desenvolvidos)\\033[0m')\n",
    "print('- \\033[1mPaíses incluídos\\033[0m: Japão, Estados Unidos, Alemanha, entre outros.')\n",
    "print('- \\033[1mJustificação\\033[0m:')\n",
    "print('  - Esses países têm indicadores socioeconômicos elevados, refletindo alto desenvolvimento.')\n",
    "print('  - \\033[1mCaracterísticas principais\\033[0m:')\n",
    "print('    - \\033[1mRenda per capita\\033[0m: Alta.')\n",
    "print('    - \\033[1mMortalidade infantil\\033[0m: Baixa.')\n",
    "print('    - \\033[1mExpectativa de vida\\033[0m: Alta.')\n",
    "\n",
    "## Observações gerais\n",
    "print('\\n\\033[1m### Observações gerais\\033[0m')\n",
    "print('- A \\033[1maltura das uniões\\033[0m no dendograma reflete as diferenças entre os grupos:')\n",
    "print('  - Clusters unidos em alturas maiores são mais heterogêneos.')\n",
    "print('  - Clusters unidos em alturas menores são mais homogêneos.')\n",
    "print('- A separação em 3 grandes clusters foi realizada com base em uma altura de corte de aproximadamente \\033[1m2.5\\033[0m no eixo Y.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 4 - Compare os dois resultados, aponte as semelhanças e diferenças e interprete. (1)\n",
    "# OUTPUT: parte3_exercicio4_comparacao_clusters.csv\n",
    "\n",
    "comparacao_clusters = dataset_normalizado[['country_code', 'Cluster_Kmeans', 'Cluster_Hierarquico']].copy()\n",
    "comparacao_clusters.loc[:, 'Country'] = comparacao_clusters['country_code'].map(numero_para_pais)\n",
    "comparacao_clusters = comparacao_clusters[['Country', 'Cluster_Kmeans', 'Cluster_Hierarquico']]\n",
    "\n",
    "# Adicionar uma coluna indicando se os clusters coincidem\n",
    "comparacao_clusters['Mesmo_Cluster'] = comparacao_clusters['Cluster_Kmeans'] == comparacao_clusters['Cluster_Hierarquico']\n",
    "\n",
    "# Exibir os primeiros 20 resultados\n",
    "print('\\033[1mParte 3 - Exercício 4 - Tabela comparativa\\033[0m\\n')\n",
    "print(comparacao_clusters.head(20))\n",
    "\n",
    "# Opcional: salvar a tabela de comparação em um arquivo CSV\n",
    "comparacao_clusters.to_csv('parte3_exercicio4_comparacao_clusters.csv', index=False)\n",
    "print('Tabela de comparação salva como \"parte3_exercicio4_comparacao_clusters.csv\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 4 - Compare os dois resultados, aponte as semelhanças e diferenças e interprete. (2)\n",
    "\n",
    "# Calcular estatísticas para a interpretação\n",
    "total_paises = len(comparacao_clusters)\n",
    "contagem_mesmo_cluster = comparacao_clusters['Mesmo_Cluster'].sum()\n",
    "proporcao_mesmo_cluster = contagem_mesmo_cluster / total_paises\n",
    "\n",
    "# Países com clusters diferentes\n",
    "clusters_diferentes = comparacao_clusters[comparacao_clusters['Mesmo_Cluster'] == False]\n",
    "\n",
    "# Exibir a interpretação\n",
    "print('\\033[1mParte 3 - Exercício 4 - Diferenças\\033[0m\\n')\n",
    "print(f'Total de países analisados: {total_paises}')\n",
    "print(f'Número de países no mesmo cluster nos dois métodos: {contagem_mesmo_cluster}')\n",
    "print(f'Proporção de países no mesmo cluster: {proporcao_mesmo_cluster:.2%}\\n')\n",
    "\n",
    "if len(clusters_diferentes) > 0:\n",
    "    print('Países classificados em clusters diferentes:')\n",
    "    print(clusters_diferentes[['Country', 'Cluster_Kmeans', 'Cluster_Hierarquico']].to_string(index=False))\n",
    "else:\n",
    "    print('Todos os países foram classificados no mesmo cluster nos dois métodos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 3 - Exercício 4 - Compare os dois resultados, aponte as semelhanças e diferenças e interprete. (3)\n",
    "# OUTPUT: parte3_exercicio4justificacao_diferencas_clusters.csv\n",
    "\n",
    "# Selecionar os países classificados de forma diferente\n",
    "diferencas_clusters = comparacao_clusters[comparacao_clusters['Mesmo_Cluster'] == False]\n",
    "\n",
    "# Obter os dados completos desses países usando a coluna 'Country'\n",
    "diferencas_dados = dataset_normalizado[dataset_normalizado['country_code'].map(numero_para_pais).isin(diferencas_clusters['Country'])]\n",
    "\n",
    "# Adicionar os clusters K-Means e Hierárquico para comparação\n",
    "diferencas_dados = diferencas_dados[['country_code'] + colunas_de_dados + ['Cluster_Kmeans', 'Cluster_Hierarquico']]\n",
    "diferencas_dados['Country'] = diferencas_dados['country_code'].map(numero_para_pais)\n",
    "\n",
    "# Reorganizar as colunas para melhor visualização\n",
    "diferencas_dados = diferencas_dados[['Country', 'Cluster_Kmeans', 'Cluster_Hierarquico'] + colunas_de_dados]\n",
    "\n",
    "# Analisar as diferenças entre os clusters\n",
    "print('\\033[1mParte 3 - Exercício 4 - Interpretação\\033[0m')\n",
    "for _, row in diferencas_dados.iterrows():\n",
    "    print(f'\\033[1m\\nPaís: {row[\"Country\"]}\\033[0m')\n",
    "    print(f'Cluster K-Means: {row[\"Cluster_Kmeans\"]} | Cluster Hierárquico: {row[\"Cluster_Hierarquico\"]}')\n",
    "    print('Características principais:')\n",
    "    for coluna in colunas_de_dados:\n",
    "        print(f'- {coluna}: {row[coluna]:.4f}')\n",
    "    print('Justificação:')\n",
    "    if row['Cluster_Kmeans'] != row['Cluster_Hierarquico']:\n",
    "        print('-> Diferença de classificação: Este país apresenta características que estão \\'na fronteira\\' entre os clusters,'\n",
    "              ' o que leva os dois métodos a classificá-lo de maneira distinta com base nas distâncias e abordagens.')\n",
    "    print('-' * 50)\n",
    "\n",
    "# Salvar as diferenças em um arquivo CSV para análise adicional\n",
    "diferencas_dados.to_csv('parte3_exercicio4_justificacao_diferencas_clusters.csv', index=False)\n",
    "print('\\nArquivo \\'parte3_exercicio4_justificacao_diferencas_clusters.csv\\' criado com os dados detalhados.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4 - Escolha de Algoritmos\n",
    "\n",
    "1. Escreva em tópicos as etapas do algoritmo de K-médias até sua convergência.\n",
    "2. O algoritmo de K-médias converge até encontrar os centróides que melhor descrevem os clusters encontrados (até o deslocamento entre as interações dos centróides ser mínimo). Lembrando que o centróide é o baricentro do cluster em questão e não representa, em via de regra, um dado existente na base. Refaça o algoritmo apresentado na questão 1 a fim de garantir que o cluster seja representado pelo dado mais próximo ao seu baricentro em todas as iterações do algoritmo.\n",
    "    - Obs: nesse novo algoritmo, o dado escolhido será chamado medóide.\n",
    "3. O algoritmo de K-médias é sensível a outliers nos dados. Explique.\n",
    "4. Por que o algoritmo de DBScan é mais robusto à presença de outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 4 - Exercício 1 - Escreva em tópicos as etapas do algoritmo de K-médias até sua convergência.\n",
    "\n",
    "print('\\033[1mParte 4 - Exercício 1 - Escreva em tópicos as etapas do algoritmo de K-médias até sua convergência.o\\033[0m')\n",
    "\n",
    "print('\\n\\033[1mEtapa 1: Escolha do número de grupos (clusters).\\033[0m')\n",
    "print('* Decisão do número de grupos para dividir os dados. Esse número é chamado de k.')\n",
    "\n",
    "print('\\n\\033[1mEtapa 2: Posicionamento inicial dos centros (centróides).\\033[0m')\n",
    "print('* Os centróides iniciais são escolhidos automaticamente pelo algoritmo de K-Means.')\n",
    "print('* No código, usei \"KMeans(n_clusters=n_clusters, random_state=20)\" para definir o número de clusters e garantir reprodutibilidade.')\n",
    "\n",
    "print('\\n\\033[1mEtapa 3: Agrupamento inicial dos pontos.\\033[0m')\n",
    "print('* Para cada ponto nos dados:')\n",
    "print('   - O algoritmo calcula qual centróide está mais próximo.')\n",
    "print('   - O ponto é então atribuído ao grupo (cluster) correspondente.')\n",
    "\n",
    "print('\\n\\033[1mEtapa 4: Ajuste dos centros dos grupos.\\033[0m')\n",
    "print('* Após a atribuição inicial:')\n",
    "print('   - O algoritmo calcula o \"novo centro\" de cada grupo.')\n",
    "print('   - Este novo centro é a posição média de todos os pontos atribuídos ao grupo.')\n",
    "print('   - Os centróides são ajustados para essas novas posições.')\n",
    "\n",
    "print('\\n\\033[1mEtapa 5: Reagrupamento dos pontos.\\033[0m')\n",
    "print('* Com os centróides ajustados:')\n",
    "print('   - Cada ponto é reavaliado para verificar qual centróide está mais próximo.')\n",
    "print('   - Se algum ponto mudar de grupo, o agrupamento é atualizado.')\n",
    "\n",
    "print('\\n\\033[1mEtapa 6: Repetição até estabilizar.\\033[0m')\n",
    "print('* O processo de ajuste e reagrupamento continua até que:')\n",
    "print('   - Nenhum ponto mude de grupo.')\n",
    "print('   - Ou o algoritmo atinja um número máximo de iterações.')\n",
    "\n",
    "print('\\n\\033[1mEtapa 7: Resultados finais.\\033[0m')\n",
    "print('* No final, o algoritmo retorna:')\n",
    "print('   - Todos os dados divididos em k grupos.')\n",
    "print('   - Os centróides finais, que representam o \"coração\" de cada grupo.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 4 - Exercício 2 - O algoritmo de K-médias converge até encontrar os centróides que melhor descrevem os clusters encontrados (até o deslocamento entre as interações dos centróides ser mínimo).\n",
    "# Lembrando que o centróide é o baricentro do cluster em questão e não representa, em via de regra, um dado existente na base.\n",
    "# Refaça o algoritmo apresentado na questão 1 a fim de garantir que o cluster seja representado pelo dado mais próximo ao seu baricentro em todas as iterações do algoritmo.\n",
    "# Obs: nesse novo algoritmo, o dado escolhido será chamado medóide.\n",
    "\n",
    "# Inicializar os medóides com índices aleatórios\n",
    "np.random.seed(20)\n",
    "indices_iniciais = np.random.choice(len(dataset_normalizado), size=n_clusters, replace=False)\n",
    "medoids = dataset_normalizado[colunas_de_dados].iloc[indices_iniciais].values\n",
    "\n",
    "# Função para calcular clusters e custo\n",
    "def atribuir_clusters_e_calcular_custo(data, medoids):\n",
    "    distancias = cdist(data, medoids, metric='euclidean')  # Distâncias Euclidianas\n",
    "    clusters = np.argmin(distancias, axis=1)  # Atribuir ao medóide mais próximo\n",
    "    custo = np.sum(np.min(distancias, axis=1))  # Soma das distâncias mínimas\n",
    "    return clusters, custo\n",
    "\n",
    "# Iterar até convergência\n",
    "medoide_anterior = None\n",
    "iteracao_kmedoid = 0\n",
    "while not np.array_equal(medoide_anterior, medoids):\n",
    "    iteracao_kmedoid += 1\n",
    "    medoide_anterior = medoids.copy()\n",
    "    # Atribuir clusters e calcular o custo\n",
    "    dataset_normalizado['Cluster_Kmedoids'], _ = atribuir_clusters_e_calcular_custo(\n",
    "        dataset_normalizado[colunas_de_dados].values, medoids\n",
    "    )\n",
    "    # Atualizar medóides para o ponto mais central do cluster\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_points = dataset_normalizado[dataset_normalizado['Cluster_Kmedoids'] == cluster][colunas_de_dados].values\n",
    "        medoid_index = np.argmin(np.sum(cdist(cluster_points, cluster_points, metric='euclidean'), axis=1))\n",
    "        medoids[cluster] = cluster_points[medoid_index]\n",
    "\n",
    "# Exibir os resultados\n",
    "print('\\033[1mParte 4 - Exercício 2 - Utilização de K-medoids\\033[0m\\n')\n",
    "\n",
    "print(f'Convergência alcançada após \\033[1m{iteracao_kmedoid}\\033[0m iterações\\n')\n",
    "\n",
    "print(\n",
    "    pd.DataFrame({\n",
    "        'Country': dataset_normalizado['country_code'].map(numero_para_pais),\n",
    "        'Cluster_Kmedoids': dataset_normalizado['Cluster_Kmedoids']\n",
    "    })\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 4 - Exercício 3 - O algoritmo de K-médias é sensível a outliers nos dados. Explique.\n",
    "\n",
    "print('\\033[1mParte 4 - Exercício 3 - O algoritmo de K-médias é sensível a outliers nos dados. Explique.\\033[0m\\n')\n",
    "\n",
    "print('\\033[1mPor que o K-Means é sensível a outliers?\\033[0m')\n",
    "print('* O algoritmo calcula os centróides como a média dos pontos no cluster.')\n",
    "print('* Outliers, que são valores muito distantes, podem deslocar o centróide, tornando-o menos representativo para a maioria dos pontos.')\n",
    "\n",
    "print('\\n\\033[1mImpacto nos agrupamentos:\\033[0m')\n",
    "print('* Os clusters podem ficar distorcidos, não refletindo bem os dados.')\n",
    "print('* Em alguns casos, os outliers podem até formar clusters próprios, atrapalhando a análise.')\n",
    "\n",
    "print('\\n\\033[1mComo evitar o problema?\\033[0m')\n",
    "print('\\033[1m1.\\033[0m Remover ou tratar os outliers antes de rodar o algoritmo.')\n",
    "print('\\033[1m2.\\033[0m Normalizar os dados para reduzir o impacto de valores extremos.')\n",
    "print('\\033[1m3.\\033[0m Considerar algoritmos mais robustos, como o K-Medoids, que usa pontos reais como representantes dos clusters.')\n",
    "\n",
    "print('\\n\\033[1mFontes:\\033[0m')\n",
    "print('* Sensibilidade do K-Médias: https://scikit-learn.org/stable/modules/clustering.html#k-means')\n",
    "print('* Comparação K-Médias e K-Medoids: https://www.geeksforgeeks.org/k-means-vs-k-medoids-clustering/')\n",
    "print('* Lidando com Outliers: https://www.datageeks.com.br/outliers/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 4 - Exercício 4 - Por que o algoritmo de DBScan é mais robusto à presença de outliers?\n",
    "\n",
    "print('\\033[1mParte 4 - Exercício 4 - Por que o algoritmo de DBScan é mais robusto à presença de outliers?\\033[0m\\n')\n",
    "\n",
    "print('\\033[1mPor que o DBSCAN é mais robusto a outliers?\\033[0m')\n",
    "print('* O algoritmo identifica automaticamente os outliers como pontos que não pertencem a nenhum cluster.')\n",
    "print('* Ele forma clusters com base na densidade de pontos, ignorando os que estão isolados.')\n",
    "print('* Diferente do K-Means, o DBSCAN não usa centróides, então outliers não deslocam os clusters.')\n",
    "print('* Pontos isolados são classificados como ruído e não afetam o agrupamento.')\n",
    "\n",
    "print('\\n\\033[1mFontes:\\033[0m')\n",
    "print('* Robustez do DBSCAN: https://scikit-learn.org/stable/modules/clustering.html#dbscan')\n",
    "print('* Comparação entre DBSCAN e K-Means: https://towardsdatascience.com/dbscan-clustering-explained-97556a2ad556')\n",
    "print('* Lidando com Outliers: https://www.datageeks.com.br/outliers/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
